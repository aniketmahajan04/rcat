This is sample file that used in developement in rcat tool.
The error you are getting is because you are trying to pass a BufReader into a method which takes a byte buffer (&[u8]). This means that you need to pass the bytes themselves into the m.update() method rather than the reader. Get used to understanding those types of compiler errors.

You can use reader.read_exact() to accomplish the task you are trying to accomplish, but you will need to pass in a buffer of the "chunk" size that you want to capture like this:

First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.

First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.

First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.

First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.
First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.
First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.
First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.
First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.First of all, save yourself some logic and use fs::read instead. Second, reading a large file is going to be slow, no way to avoid it. However, you're essentially blocking the rendering of the file on reading the entire file, so you're not really benefiting from async at all. A better approach would be to read and render the file in chunks, though this will probably require some significant refactoring.
